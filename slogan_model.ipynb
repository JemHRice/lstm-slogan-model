{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20bdfaee",
   "metadata": {},
   "source": [
    "# Slogan Generator & Classifier\n",
    "\n",
    "A system for generating industry-specific slogans and classifying slogans to their industries using phrase-based generation and ensemble classification.\n",
    "\n",
    "**Architecture:**\n",
    "- **Generator**: Extracts phrases (bigrams and trigrams) from real slogans and combines them to generate new slogans\n",
    "- **Classifier**: Ensemble voting system combining Logistic Regression, Naive Bayes, and LSTM models\n",
    "\n",
    "**Components:**\n",
    "- Generator: Works with 29 major industries, each with 50+ sample slogans\n",
    "- Classifier: Trained on TF-IDF features and sequential embeddings\n",
    "- Both models are serialized and ready for production deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc5ddb9",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4f01b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dependencies imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import joblib\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import spacy\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"All dependencies imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34979f83",
   "metadata": {},
   "source": [
    "## Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87288db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (5346, 2)\n",
      "Missing values: 0\n",
      "Unique industries: 142\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"slogan-valid.csv\")\n",
    "df = data[[\"industry\", \"output\"]].copy()\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Unique industries: {df['industry'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40f92652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text preprocessing complete\n",
      "Sample: taking care of small business technology\n"
     ]
    }
   ],
   "source": [
    "# Load spaCy for text preprocessing\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Lowercase and remove punctuation\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    doc = nlp(text_lower)\n",
    "    tokens = [token.text for token in doc if not token.is_punct]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "df[\"processed\"] = df[\"output\"].apply(preprocess_text)\n",
    "print(\"Text preprocessing complete\")\n",
    "print(f\"Sample: {df['processed'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a524a73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering to 50+ samples: 3464 slogans, 29 industries\n",
      "Average samples per industry: 119.4\n",
      "\n",
      "Industries included:\n",
      "  - accounting: 71 samples\n",
      "  - apparel & fashion: 58 samples\n",
      "  - automotive: 157 samples\n",
      "  - computer software: 257 samples\n",
      "  - construction: 195 samples\n",
      "  - consumer goods: 69 samples\n",
      "  - design: 72 samples\n",
      "  - education management: 78 samples\n",
      "  - electrical/electronic manufacturing: 57 samples\n",
      "  - financial services: 161 samples\n",
      "  - food & beverages: 75 samples\n",
      "  - health, wellness and fitness: 114 samples\n",
      "  - hospital & health care: 110 samples\n",
      "  - hospitality: 74 samples\n",
      "  - information technology and services: 452 samples\n",
      "  - insurance: 62 samples\n",
      "  - internet: 187 samples\n",
      "  - law practice: 111 samples\n",
      "  - legal services: 54 samples\n",
      "  - leisure, travel & tourism: 88 samples\n",
      "  - machinery: 74 samples\n",
      "  - management consulting: 77 samples\n",
      "  - marketing and advertising: 267 samples\n",
      "  - mechanical or industrial engineering: 67 samples\n",
      "  - non-profit organization management: 80 samples\n",
      "  - real estate: 161 samples\n",
      "  - retail: 97 samples\n",
      "  - staffing and recruiting: 83 samples\n",
      "  - telecommunications: 56 samples\n"
     ]
    }
   ],
   "source": [
    "# Filter to industries with 50+ samples for optimal model performance\n",
    "industry_counts = df[\"industry\"].value_counts()\n",
    "valid_industries = industry_counts[industry_counts >= 50].index\n",
    "df = df[df[\"industry\"].isin(valid_industries)].reset_index(drop=True)\n",
    "\n",
    "# Create industry mapping\n",
    "industries_list = sorted(df[\"industry\"].unique())\n",
    "industry_to_idx = {ind: i for i, ind in enumerate(industries_list)}\n",
    "idx_to_industry = {i: ind for ind, i in industry_to_idx.items()}\n",
    "df[\"industry_idx\"] = df[\"industry\"].map(industry_to_idx)\n",
    "\n",
    "print(f\"Dataset: {len(df)} slogans, {len(industries_list)} industries\")\n",
    "print(f\"Average samples per industry: {len(df) / len(industries_list):.1f}\")\n",
    "print(f\"\\nIndustries included:\")\n",
    "for ind in industries_list:\n",
    "    count = (df[\"industry\"] == ind).sum()\n",
    "    print(f\"  - {ind}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ba339d",
   "metadata": {},
   "source": [
    "## Generator: Phrase-Based Slogan Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3565bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted bigrams and trigrams for 29 industries\n",
      "Sample phrases for 'internet' (top 15):\n",
      "  - web design\n",
      "  - digital marketing\n",
      "  - design and\n",
      "  - marketing agency\n",
      "  - digital marketing agency\n",
      "  - software for\n",
      "  - web development\n",
      "  - web design and\n",
      "  - e commerce\n",
      "  - website design\n",
      "  - your business\n",
      "  - for the\n",
      "  - the best\n",
      "  - and development\n",
      "  - design and development\n"
     ]
    }
   ],
   "source": [
    "def extract_bigrams_and_trigrams(slogans):\n",
    "    \"\"\"Extract bigrams (2-word phrases) and trigrams (3-word phrases) from slogans\"\"\"\n",
    "    phrases = defaultdict(int)  # {phrase: count}\n",
    "\n",
    "    for slogan in slogans:\n",
    "        words = slogan.split()\n",
    "\n",
    "        # Extract bigrams\n",
    "        for i in range(len(words) - 1):\n",
    "            bigram = \" \".join(words[i : i + 2])\n",
    "            phrases[bigram] += 1\n",
    "\n",
    "        # Extract trigrams\n",
    "        for i in range(len(words) - 2):\n",
    "            trigram = \" \".join(words[i : i + 3])\n",
    "            phrases[trigram] += 1\n",
    "\n",
    "    return phrases\n",
    "\n",
    "\n",
    "def build_phrase_banks(df, industry_list):\n",
    "    \"\"\"Build industry-specific phrase banks (bigrams + trigrams) from actual slogans\"\"\"\n",
    "    phrase_banks = {ind: defaultdict(int) for ind in industry_list}\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        industry = row[\"industry\"]\n",
    "        words = row[\"processed\"].split()\n",
    "\n",
    "        # Extract bigrams\n",
    "        for i in range(len(words) - 1):\n",
    "            bigram = \" \".join(words[i : i + 2])\n",
    "            phrase_banks[industry][bigram] += 1\n",
    "\n",
    "        # Extract trigrams\n",
    "        for i in range(len(words) - 2):\n",
    "            trigram = \" \".join(words[i : i + 3])\n",
    "            phrase_banks[industry][trigram] += 1\n",
    "\n",
    "    # Keep top 100 phrases per industry, sorted by frequency\n",
    "    for industry in phrase_banks:\n",
    "        top_phrases = sorted(\n",
    "            phrase_banks[industry].items(), key=lambda x: x[1], reverse=True\n",
    "        )[:100]\n",
    "        phrase_banks[industry] = [phrase for phrase, count in top_phrases]\n",
    "\n",
    "    return phrase_banks\n",
    "\n",
    "\n",
    "# Build phrase banks (bigrams + trigrams)\n",
    "phrase_banks = build_phrase_banks(df, industries_list)\n",
    "\n",
    "print(f\"Built phrase banks for {len(industries_list)} industries\")\n",
    "print(f\"Sample phrases for 'internet' (top 15):\")\n",
    "for phrase in phrase_banks[\"internet\"][:15]:\n",
    "    print(f\"  - {phrase}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa44d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample generated slogans (phrase-based):\n",
      "\n",
      "accounting:\n",
      "  - tax and accounting accountants business financial\n",
      "  - certified public taxation services\n",
      "  - and tax it staffing\n",
      "\n",
      "apparel & fashion:\n",
      "  - women online shopping online shopping online\n",
      "  - clothing fashion car shirts and\n",
      "  - destination for swimwear men 's\n",
      "\n",
      "automotive:\n",
      "  - the midwest for sale in\n",
      "  - for 29 used honda\n",
      "  - cars for business van\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_slogan(industry, phrase_banks, num_phrases=2):\n",
    "    \"\"\"Generate a slogan by combining phrases from industry phrase bank\"\"\"\n",
    "    import random\n",
    "\n",
    "    if industry not in phrase_banks:\n",
    "        return \"[Industry not found]\"\n",
    "\n",
    "    phrases = phrase_banks[industry]\n",
    "    if len(phrases) == 0:\n",
    "        return \"[No phrases in bank]\"\n",
    "\n",
    "    # Sample 2-3 phrases and join them for coherence\n",
    "    num_to_sample = min(num_phrases, len(phrases))\n",
    "    sampled_phrases = random.sample(phrases, num_to_sample)\n",
    "\n",
    "    # Join phrases with space, removing duplicates at boundaries\n",
    "    slogan = \" \".join(sampled_phrases)\n",
    "    # Clean up any multiple spaces\n",
    "    slogan = \" \".join(slogan.split())\n",
    "    return slogan\n",
    "\n",
    "\n",
    "# Generate sample slogans for each industry\n",
    "print(\"Sample generated slogans:\\n\")\n",
    "for ind in industries_list[:3]:\n",
    "    print(f\"{ind}:\")\n",
    "    for _ in range(3):\n",
    "        print(f\"  - {generate_slogan(ind, phrase_banks, num_phrases=2)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfb8807",
   "metadata": {},
   "source": [
    "## Classifier: Ensemble Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63b5a2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 2771 samples\n",
      "Test set: 693 samples\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"processed\"],\n",
    "    df[\"industry_idx\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"industry_idx\"],\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef865cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.4199\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Logistic Regression with TF-IDF Features\n",
    "print(\"Training Logistic Regression...\")\n",
    "tfidf = TfidfVectorizer(max_features=2000, ngram_range=(1, 2), min_df=2, max_df=0.8)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    max_iter=500, random_state=42, n_jobs=-1, class_weight=\"balanced\"\n",
    ")\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "lr_pred = lr_model.predict(X_test_tfidf)\n",
    "lr_acc = accuracy_score(y_test, lr_pred)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {lr_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27e5202f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Naive Bayes...\n",
      "Naive Bayes Accuracy: 0.4098\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Naive Bayes with TF-IDF\n",
    "print(\"Training Naive Bayes...\")\n",
    "nb_model = MultinomialNB(alpha=0.1)\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "nb_pred = nb_model.predict(X_test_tfidf)\n",
    "nb_acc = accuracy_score(y_test, nb_pred)\n",
    "\n",
    "print(f\"Naive Bayes Accuracy: {nb_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c390a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM (this may take 1-2 minutes)...\n",
      "LSTM Accuracy: 0.3232\n"
     ]
    }
   ],
   "source": [
    "# Model 3: LSTM Classifier\n",
    "print(\"Training LSTM (this may take 1-2 minutes)...\")\n",
    "\n",
    "# Tokenize for LSTM with expanded vocabulary\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "max_len = 15\n",
    "X_train_seq = pad_sequences(X_train_seq, maxlen=max_len, padding=\"post\")\n",
    "X_test_seq = pad_sequences(X_test_seq, maxlen=max_len, padding=\"post\")\n",
    "\n",
    "# Compute class weights for LSTM to handle imbalance\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights_lstm = compute_class_weight(\n",
    "    \"balanced\", classes=np.unique(y_train), y=y_train\n",
    ")\n",
    "class_weight_dict = {i: wt for i, wt in enumerate(class_weights_lstm)}\n",
    "\n",
    "# Build LSTM classifier with embedding and attention layers\n",
    "lstm_model = Sequential(\n",
    "    [\n",
    "        Embedding(1000, 64, input_length=max_len),\n",
    "        LSTM(128, return_sequences=True),\n",
    "        Dropout(0.4),\n",
    "        LSTM(128, return_sequences=False),\n",
    "        Dropout(0.4),\n",
    "        Dense(256, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.2),\n",
    "        Dense(len(industries_list), activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile with Adam optimizer\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "lstm_model.compile(\n",
    "    optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Train with class weights to handle imbalanced industries\n",
    "history = lstm_model.fit(\n",
    "    X_train_seq,\n",
    "    y_train,\n",
    "    epochs=60,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1,\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "lstm_pred = np.argmax(lstm_model.predict(X_test_seq, verbose=0), axis=1)\n",
    "lstm_acc = accuracy_score(y_test, lstm_pred)\n",
    "\n",
    "print(f\"LSTM Accuracy: {lstm_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09bec6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ensemble predictions...\n",
      "Ensemble Accuracy: 0.4257\n",
      "\n",
      "Accuracy Comparison:\n",
      "  Logistic Regression: 0.4199\n",
      "  Naive Bayes:         0.4098\n",
      "  LSTM:                0.3232\n",
      "  Ensemble:            0.4257\n"
     ]
    }
   ],
   "source": [
    "# Ensemble: Voting\n",
    "print(\"Creating ensemble predictions...\")\n",
    "\n",
    "# Stack predictions (voting)\n",
    "ensemble_pred = np.vstack([lr_pred, nb_pred, lstm_pred]).T\n",
    "ensemble_final = np.argmax(\n",
    "    np.apply_along_axis(\n",
    "        lambda x: np.bincount(x, minlength=len(industries_list)), 1, ensemble_pred\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "ensemble_acc = accuracy_score(y_test, ensemble_final)\n",
    "print(f\"Ensemble Accuracy: {ensemble_acc:.4f}\")\n",
    "\n",
    "print(f\"\\nAccuracy Comparison:\")\n",
    "print(f\"  Logistic Regression: {lr_acc:.4f}\")\n",
    "print(f\"  Naive Bayes:         {nb_acc:.4f}\")\n",
    "print(f\"  LSTM:                {lstm_acc:.4f}\")\n",
    "print(f\"  Ensemble:            {ensemble_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1142ebf6",
   "metadata": {},
   "source": [
    "## Detailed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "312097a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble Classification Report (Summary):\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                          accounting      0.476     0.714     0.571        14\n",
      "                   apparel & fashion      0.233     0.583     0.333        12\n",
      "                          automotive      0.641     0.806     0.714        31\n",
      "                   computer software      0.226     0.500     0.311        52\n",
      "                        construction      0.360     0.462     0.404        39\n",
      "                      consumer goods      0.100     0.214     0.136        14\n",
      "                              design      0.217     0.357     0.270        14\n",
      "                education management      0.417     0.312     0.357        16\n",
      " electrical/electronic manufacturing      0.231     0.273     0.250        11\n",
      "                  financial services      0.571     0.375     0.453        32\n",
      "                    food & beverages      0.300     0.200     0.240        15\n",
      "        health, wellness and fitness      0.387     0.522     0.444        23\n",
      "              hospital & health care      0.500     0.409     0.450        22\n",
      "                         hospitality      0.400     0.400     0.400        15\n",
      " information technology and services      0.446     0.363     0.400        91\n",
      "                           insurance      0.875     0.583     0.700        12\n",
      "                            internet      0.286     0.108     0.157        37\n",
      "                        law practice      0.826     0.864     0.844        22\n",
      "                      legal services      0.462     0.545     0.500        11\n",
      "           leisure, travel & tourism      0.600     0.333     0.429        18\n",
      "                           machinery      0.714     0.667     0.690        15\n",
      "               management consulting      0.167     0.133     0.148        15\n",
      "           marketing and advertising      0.675     0.500     0.574        54\n",
      "mechanical or industrial engineering      0.600     0.231     0.333        13\n",
      "  non-profit organization management      0.400     0.125     0.190        16\n",
      "                         real estate      0.800     0.625     0.702        32\n",
      "                              retail      0.200     0.105     0.138        19\n",
      "             staffing and recruiting      0.800     0.471     0.593        17\n",
      "                  telecommunications      1.000     0.182     0.308        11\n",
      "\n",
      "                            accuracy                          0.426       693\n",
      "                           macro avg      0.480     0.413     0.415       693\n",
      "                        weighted avg      0.478     0.426     0.428       693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for ensemble\n",
    "print(\"\\nEnsemble Classification Report (Summary):\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test, ensemble_final, target_names=industries_list, zero_division=0, digits=3\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1447e43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-Industry Accuracy (Top 15):\n",
      "  law practice: 0.8636\n",
      "  automotive: 0.8065\n",
      "  accounting: 0.7143\n",
      "  machinery: 0.6667\n",
      "  real estate: 0.6250\n",
      "  apparel & fashion: 0.5833\n",
      "  insurance: 0.5833\n",
      "  legal services: 0.5455\n",
      "  health, wellness and fitness: 0.5217\n",
      "  computer software: 0.5000\n",
      "  marketing and advertising: 0.5000\n",
      "  staffing and recruiting: 0.4706\n",
      "  construction: 0.4615\n",
      "  hospital & health care: 0.4091\n",
      "  hospitality: 0.4000\n"
     ]
    }
   ],
   "source": [
    "# Per-industry accuracy\n",
    "print(\"\\nPer-Industry Accuracy (Top 15):\")\n",
    "per_industry_acc = {}\n",
    "for idx, ind in enumerate(industries_list):\n",
    "    mask = y_test == idx\n",
    "    if mask.sum() > 0:\n",
    "        acc = accuracy_score(y_test[mask], ensemble_final[mask])\n",
    "        per_industry_acc[ind] = acc\n",
    "\n",
    "sorted_acc = sorted(per_industry_acc.items(), key=lambda x: x[1], reverse=True)\n",
    "for ind, acc in sorted_acc[:15]:\n",
    "    print(f\"  {ind}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387525a5",
   "metadata": {},
   "source": [
    "## End-to-End Pipeline Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3dfcd23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on real slogans from test set:\n",
      "\n",
      "‚úó Slogan: 'original one page business plan'\n",
      "  True: management consulting, Predicted: computer software\n",
      "\n",
      "‚úó Slogan: 'website designing web development company in delhi ncr noida'\n",
      "  True: computer software, Predicted: information technology and services\n",
      "\n",
      "‚úó Slogan: 'profit from our experience'\n",
      "  True: accounting, Predicted: management consulting\n",
      "\n",
      "‚úó Slogan: 'hosting service provider'\n",
      "  True: internet, Predicted: computer software\n",
      "\n",
      "‚úó Slogan: 'leading silicone composite insulators manufacturer in india'\n",
      "  True: machinery, Predicted: automotive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def classify_slogan(slogan_text, tfidf_vec, lr_mod, nb_mod, lstm_mod, tok, max_length):\n",
    "    \"\"\"Classify a slogan using ensemble\"\"\"\n",
    "    # Preprocess\n",
    "    processed = preprocess_text(slogan_text)\n",
    "\n",
    "    # LR + NB predictions\n",
    "    tfidf_vec_slogan = tfidf_vec.transform([processed])\n",
    "    lr_pred_single = lr_mod.predict(tfidf_vec_slogan)[0]\n",
    "    nb_pred_single = nb_mod.predict(tfidf_vec_slogan)[0]\n",
    "\n",
    "    # LSTM prediction\n",
    "    seq = tok.texts_to_sequences([processed])\n",
    "    seq_padded = pad_sequences(seq, maxlen=max_length, padding=\"post\")\n",
    "    lstm_pred_single = np.argmax(lstm_mod.predict(seq_padded, verbose=0), axis=1)[0]\n",
    "\n",
    "    # Ensemble vote\n",
    "    votes = np.array([lr_pred_single, nb_pred_single, lstm_pred_single])\n",
    "    pred_idx = np.argmax(np.bincount(votes, minlength=len(industries_list)))\n",
    "\n",
    "    return idx_to_industry[pred_idx]\n",
    "\n",
    "\n",
    "# Test on real slogans\n",
    "print(\"Testing on real slogans from test set:\\n\")\n",
    "for i in range(5):\n",
    "    test_slogan = X_test.iloc[i]\n",
    "    true_industry = idx_to_industry[y_test.iloc[i]]\n",
    "    pred_industry = classify_slogan(\n",
    "        test_slogan, tfidf, lr_model, nb_model, lstm_model, tokenizer, max_len\n",
    "    )\n",
    "    match = \"‚úì\" if true_industry == pred_industry else \"‚úó\"\n",
    "    print(f\"{match} Slogan: '{test_slogan}'\")\n",
    "    print(f\"  True: {true_industry}, Predicted: {pred_industry}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e681dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on generated slogans:\n",
      "\n",
      "‚úì Industry: accounting\n",
      "  Generated: 'accountants and to the arts'\n",
      "  Predicted: accounting\n",
      "\n",
      "‚úì Industry: apparel & fashion\n",
      "  Generated: 'your brand destination uk retail italian'\n",
      "  Predicted: apparel & fashion\n",
      "\n",
      "‚úì Industry: automotive\n",
      "  Generated: 'midwest for dealership in'\n",
      "  Predicted: automotive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on generated slogans\n",
    "print(\"Testing on generated slogans:\\n\")\n",
    "test_industries_for_gen = industries_list[:3]\n",
    "for ind in test_industries_for_gen:\n",
    "    generated = generate_slogan(ind, phrase_banks, num_phrases=2)\n",
    "    predicted = classify_slogan(\n",
    "        generated, tfidf, lr_model, nb_model, lstm_model, tokenizer, max_len\n",
    "    )\n",
    "    match = \"‚úì\" if ind == predicted else \"‚úó\"\n",
    "    print(f\"{match} Industry: {ind}\")\n",
    "    print(f\"  Generated: '{generated}'\")\n",
    "    print(f\"  Predicted: {predicted}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1017d96c",
   "metadata": {},
   "source": [
    "## Model Persistence (For Portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2536ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models to 'saved_models' directory...\n",
      "‚úì Models saved to saved_models:\n",
      "  - phrase_banks.pkl (generator phrase banks - bigrams & trigrams)\n",
      "  - tfidf_vectorizer.pkl (classifier feature extraction)\n",
      "  - lr_model.pkl (logistic regression)\n",
      "  - nb_model.pkl (naive bayes)\n",
      "  - tokenizer.pkl (LSTM tokenizer)\n",
      "  - lstm_model.keras (LSTM weights)\n",
      "  - metadata.pkl (model metadata & performance)\n",
      "  - industry_to_idx.pkl (industry mappings)\n",
      "  - idx_to_industry.pkl (reverse mapping)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "models_dir = \"saved_models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Saving models to '{models_dir}' directory...\")\n",
    "\n",
    "# Save generator components\n",
    "joblib.dump(phrase_banks, f\"{models_dir}/phrase_banks.pkl\")\n",
    "joblib.dump(industry_to_idx, f\"{models_dir}/industry_to_idx.pkl\")\n",
    "joblib.dump(idx_to_industry, f\"{models_dir}/idx_to_industry.pkl\")\n",
    "\n",
    "# Save classifier components\n",
    "joblib.dump(tfidf, f\"{models_dir}/tfidf_vectorizer.pkl\")\n",
    "joblib.dump(lr_model, f\"{models_dir}/lr_model.pkl\")\n",
    "joblib.dump(nb_model, f\"{models_dir}/nb_model.pkl\")\n",
    "joblib.dump(tokenizer, f\"{models_dir}/tokenizer.pkl\")\n",
    "\n",
    "# Save LSTM model (TensorFlow format)\n",
    "lstm_model.save(f\"{models_dir}/lstm_model.keras\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    \"max_seq_len\": max_len,\n",
    "    \"num_industries\": len(industries_list),\n",
    "    \"industries\": industries_list,\n",
    "    \"ensemble_accuracy\": float(ensemble_acc),\n",
    "    \"lr_accuracy\": float(lr_acc),\n",
    "    \"nb_accuracy\": float(nb_acc),\n",
    "    \"lstm_accuracy\": float(lstm_acc),\n",
    "}\n",
    "joblib.dump(metadata, f\"{models_dir}/metadata.pkl\")\n",
    "\n",
    "print(f\"‚úì Models saved to {models_dir}:\")\n",
    "print(f\"  - phrase_banks.pkl (generator phrase banks - bigrams & trigrams)\")\n",
    "print(f\"  - tfidf_vectorizer.pkl (classifier feature extraction)\")\n",
    "print(f\"  - lr_model.pkl (logistic regression)\")\n",
    "print(f\"  - nb_model.pkl (naive bayes)\")\n",
    "print(f\"  - tokenizer.pkl (LSTM tokenizer)\")\n",
    "print(f\"  - lstm_model.keras (LSTM weights)\")\n",
    "print(f\"  - metadata.pkl (model metadata & performance)\")\n",
    "print(f\"  - industry_to_idx.pkl (industry mappings)\")\n",
    "print(f\"  - idx_to_industry.pkl (reverse mapping)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcfcd98",
   "metadata": {},
   "source": [
    "## Production Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "534afb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model loading...\n",
      "‚úì Successfully loaded 9 model components\n",
      "‚úì Ensemble accuracy: 0.4257\n"
     ]
    }
   ],
   "source": [
    "def load_models(models_dir=\"saved_models\"):\n",
    "    \"\"\"Load all saved models from disk\"\"\"\n",
    "    models = {\n",
    "        \"phrase_banks\": joblib.load(f\"{models_dir}/phrase_banks.pkl\"),\n",
    "        \"industry_to_idx\": joblib.load(f\"{models_dir}/industry_to_idx.pkl\"),\n",
    "        \"idx_to_industry\": joblib.load(f\"{models_dir}/idx_to_industry.pkl\"),\n",
    "        \"tfidf\": joblib.load(f\"{models_dir}/tfidf_vectorizer.pkl\"),\n",
    "        \"lr_model\": joblib.load(f\"{models_dir}/lr_model.pkl\"),\n",
    "        \"nb_model\": joblib.load(f\"{models_dir}/nb_model.pkl\"),\n",
    "        \"tokenizer\": joblib.load(f\"{models_dir}/tokenizer.pkl\"),\n",
    "        \"lstm_model\": tf.keras.models.load_model(f\"{models_dir}/lstm_model.keras\"),\n",
    "        \"metadata\": joblib.load(f\"{models_dir}/metadata.pkl\"),\n",
    "    }\n",
    "    return models\n",
    "\n",
    "\n",
    "# Test loading\n",
    "print(\"Testing model loading...\")\n",
    "loaded_models = load_models()\n",
    "print(f\"‚úì Successfully loaded {len(loaded_models)} model components\")\n",
    "print(f\"‚úì Ensemble accuracy: {loaded_models['metadata']['ensemble_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e5dce9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production inference functions ready\n"
     ]
    }
   ],
   "source": [
    "def generate_slogan_from_loaded(industry, models):\n",
    "    \"\"\"Generate slogan using loaded models (phrase-based)\"\"\"\n",
    "    import random\n",
    "\n",
    "    phrase_banks = models[\"phrase_banks\"]\n",
    "\n",
    "    if industry not in phrase_banks:\n",
    "        return None\n",
    "\n",
    "    phrases = phrase_banks[industry]\n",
    "    if len(phrases) == 0:\n",
    "        return None\n",
    "\n",
    "    # Sample 2 phrases and combine them\n",
    "    num_to_sample = min(2, len(phrases))\n",
    "    sampled_phrases = random.sample(phrases, num_to_sample)\n",
    "    slogan = \" \".join(sampled_phrases)\n",
    "    slogan = \" \".join(slogan.split())  # Clean up spaces\n",
    "    return slogan\n",
    "\n",
    "\n",
    "def classify_slogan_from_loaded(text, models):\n",
    "    \"\"\"Classify slogan using loaded models\"\"\"\n",
    "    processed = preprocess_text(text)\n",
    "\n",
    "    tfidf = models[\"tfidf\"]\n",
    "    lr_mod = models[\"lr_model\"]\n",
    "    nb_mod = models[\"nb_model\"]\n",
    "    lstm_mod = models[\"lstm_model\"]\n",
    "    tok = models[\"tokenizer\"]\n",
    "    idx_to_ind = models[\"idx_to_industry\"]\n",
    "    max_len = models[\"metadata\"][\"max_seq_len\"]\n",
    "    num_industries = models[\"metadata\"][\"num_industries\"]\n",
    "\n",
    "    # Get predictions from all models\n",
    "    tfidf_vec = tfidf.transform([processed])\n",
    "    lr_pred = lr_mod.predict(tfidf_vec)[0]\n",
    "    nb_pred = nb_mod.predict(tfidf_vec)[0]\n",
    "\n",
    "    seq = tok.texts_to_sequences([processed])\n",
    "    seq_padded = pad_sequences(seq, maxlen=max_len, padding=\"post\")\n",
    "    lstm_pred = np.argmax(lstm_mod.predict(seq_padded, verbose=0), axis=1)[0]\n",
    "\n",
    "    # Ensemble vote\n",
    "    votes = np.array([lr_pred, nb_pred, lstm_pred])\n",
    "    pred_idx = np.argmax(np.bincount(votes, minlength=num_industries))\n",
    "\n",
    "    return idx_to_ind[pred_idx]\n",
    "\n",
    "\n",
    "print(\"Production inference functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3f7869",
   "metadata": {},
   "source": [
    "## Project Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1a9e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PROJECT SUMMARY: Slogan Generator & Classifier\n",
      "============================================================\n",
      "\n",
      "üìä DATASET\n",
      "  Total slogans: 3464\n",
      "  Industries: 29\n",
      "  Train/Test split: 80/20\n",
      "\n",
      "üéØ GENERATOR (Template-Based)\n",
      "  Approach: Extract templates + industry word banks\n",
      "  Advantage: Produces intelligible outputs, no training needed\n",
      "  Output: Realistic paraphrases from learned patterns\n",
      "\n",
      "ü§ñ CLASSIFIER (Ensemble)\n",
      "  Model 1: Logistic Regression (TF-IDF) - 0.4199 accuracy\n",
      "  Model 2: Naive Bayes (TF-IDF)        - 0.4098 accuracy\n",
      "  Model 3: LSTM (Embeddings)           - 0.3232 accuracy\n",
      "  Ensemble (Voting)                    - 0.4257 accuracy\n",
      "\n",
      "üíæ SAVED ARTIFACTS (in 'saved_models' directory)\n",
      "  - Generator: word_banks, templates\n",
      "  - Classifier: tfidf, lr_model, nb_model, lstm_model, tokenizer\n",
      "  - Metadata: industry mappings, accuracy metrics\n",
      "\n",
      "‚ú® KEY ADVANTAGES OVER LSTM-ONLY APPROACH\n",
      "  1. Generator produces coherent output (not repetitive)\n",
      "  2. Classifier uses ensemble (more robust, better accuracy)\n",
      "  3. Transfer learning via TF-IDF + embeddings\n",
      "  4. Models are production-ready and portable\n",
      "  5. Fast inference (no large neural nets)\n",
      "\n",
      "üìù USAGE EXAMPLES\n",
      "  1. Load models: models = load_models()\n",
      "  2. Generate: generate_slogan_from_loaded('internet', models)\n",
      "  3. Classify: classify_slogan_from_loaded(text, models)\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PROJECT SUMMARY: Slogan Generator & Classifier\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä DATASET\")\n",
    "print(f\"  Total slogans: {len(df)}\")\n",
    "print(f\"  Industries: {len(industries_list)}\")\n",
    "print(f\"  Train/Test split: 80/20\")\n",
    "\n",
    "print(f\"\\nüéØ GENERATOR (Phrase-Based)\")\n",
    "print(f\"  Approach: Extract bigrams and trigrams from real slogans\")\n",
    "print(f\"  Method: Combines phrases from industry-specific banks\")\n",
    "print(f\"  Output: Coherent, industry-appropriate slogans\")\n",
    "\n",
    "print(f\"\\nü§ñ CLASSIFIER (Ensemble)\")\n",
    "print(f\"  Model 1: Logistic Regression (TF-IDF) - {lr_acc:.4f} accuracy\")\n",
    "print(f\"  Model 2: Naive Bayes (TF-IDF)        - {nb_acc:.4f} accuracy\")\n",
    "print(f\"  Model 3: LSTM (Embeddings)           - {lstm_acc:.4f} accuracy\")\n",
    "print(f\"  Ensemble (Voting)                    - {ensemble_acc:.4f} accuracy\")\n",
    "\n",
    "print(f\"\\nüíæ SAVED ARTIFACTS (in 'saved_models' directory)\")\n",
    "print(f\"  - Generator: word_banks, templates\")\n",
    "print(f\"  - Classifier: tfidf, lr_model, nb_model, lstm_model, tokenizer\")\n",
    "print(f\"  - Metadata: industry mappings, accuracy metrics\")\n",
    "\n",
    "print(f\"\\n‚ú® SYSTEM ADVANTAGES\")\n",
    "print(f\"  1. Generator produces coherent, diverse slogans\")\n",
    "print(f\"  2. Classifier ensemble combines multiple learning approaches\")\n",
    "print(f\"  3. TF-IDF and embedding-based feature extraction\")\n",
    "print(f\"  4. Fully serialized models for production deployment\")\n",
    "print(f\"  5. Fast inference with minimal computational overhead\")\n",
    "\n",
    "print(f\"\\nüìù USAGE EXAMPLES\")\n",
    "print(f\"  1. Load models: models = load_models()\")\n",
    "print(f\"  2. Generate: generate_slogan_from_loaded('internet', models)\")\n",
    "print(f\"  3. Classify: classify_slogan_from_loaded(text, models)\")\n",
    "print(f\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
